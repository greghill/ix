

\section{Related Work}
\label{sec:related}

We organize the discussion topically, while avoiding redundancy with
the commentary already exposed in \S\ref{sec:motivation:current}.


\myparagraph{Separation of control and data plane:} The notion of
architected separation between control and data plane is pervasive in
the design of networking protocols and devices.  In systems,
virtualization also separates the control and execution functions. For
example, type-2
hypervisors~\cite{DBLP:journals/tocs/BugnionDRSW12,misc/kivity07kvm}
use a Linux environment for control, and a separate virtualization
module for execution.  We leverage Dune and the same virtualization
hardware to run the \ix as a process of the control plane.
Arrakis~\cite{peter2013arrakis,arrakisTR13} recently proposed to
separate the networking stack into a distinct dataplane.  Our work
most closely ressembles Arrakis, but with noticeable differences:
first, Arrakis uses the Barrelfish multikernel~\cite{DBLP:conf/sosp/BaumannBDHIPRSS09} as its control plane
and run-time layer, whereas the \ix control plane runs on a vanilla
Linux foundation.  Second, Arrakis runs its own, homegrown, networking
stack at userlevel, whereas \ix runs its networking stack
protected from the application.

\myparagraph{Library operating systems:}
In an Exokernel, the role of the kernel is limited to the
multiplexing of hardware resources, and all abstractions are
implemented by library operating systems linked with
applications~\cite{DBLP:conf/sosp/EnglerKO95}; the authors observe
that applications are best suited to implement abstractions, as an
application of the end-to-end
principle~\cite{DBLP:journals/tocs/SaltzerRC84}.  Disco proposed to
use hardware virtualization to run specialized operating systems
running a single application~\cite{DBLP:journals/tocs/BugnionDGR97}, a
case also made more recently by Unikernels in the context of
XXX~\cite{DBLP:conf/asplos/MadhavapeddyMRSSGSHC13}.  \ix builds on
these notions: the control plane merely multiplexes hardware resources
among dataplanes; the \ix kernel is a single-application operating
system using hardware virtualization for protection; finally, \ix
applies the end-to-end principle by safely exposing TCP flow control
to applications without the need for additional abstractions.


\myparagraph{User-level networking stacks:} Our work shares the same
motivation as mTCP~\cite{jeong2014mtcp} and
Sandstorm~\cite{marinos2013network} in offering a specialized
networking stack.  mTCP and \ix both focus on
providing highly-scalable
networking stack for web-scale applications, including in the presence
of high connection count and churn; both also bound the
latency of RPC, and were designed to use the same standard Intel NIC.
mTCP has an asymmetrical model where the first hyperthread of each
core runs the networking stack and the second one the application.
Also, the application and networking stack share the same address
space without any memory protection.  \ix can use both hyperthreads symmetrically
and protects the protocol stack.  \edb{PLACEHOLDER:} Our results show
that, for the same workloads, \ix typically outperforms mTCP by 3x on
CPU-bound workloads, and provides lower latency.
 

\myparagraph{Hardware and protocol specialization:} Our work applies
specialization in software to commodity servers and networking
equipment.  Although our work shows that latencies and jitter can be
substantially reduced, on the same hardware, by using \ix rather than
standard Linux stacks or even userlevel stacks, we are still outside
of the latency range enabled by specialized adapters that expose RDMA
directly to applications.  Commercial Infiniband RDMA adapters offer
RDMA and remote procedure calls in
\mbox{1--3}\microsecond~\cite{DBLP:conf/sosp/OngaroRSOR11,Jose:2011:MDH,mitchell:rdma,dragojevic14farm}.
Our current evaluation of \ix suggests that there is still room for
improvements.  Indeed, on the same hardware, we've measured UDP
one-way latencies that were a fraction of the NetPIPE latencies,
suggesting that the TCP codebase could be substantially optimized in
future work. \adam{CHECK?}

\myparagraph{Asynchronous and zero-copy interactions:} Many systems
address the system interaction limitations of the POSIX model, and in
particular inability to batch requests across sockets.
FlexSC~\cite{soares2010flexsc} provides batched, exception-less system
calls.  MegaPipe~\cite{han2012megapipe}, NetMap~\cite{rizzo2012netmap}
and mTCP replace individual socket calls with in-memory pipes for
communication between the networking stack and the application.  Some
synchronization is required to protect the concurrent access to that
ring because of the asynchronous execution of the two components.  In
contrast, \ix uses an array mechanisms and an interleaved execution
model, which enables coherence-free execution.  The semantics of POSIX
sockets also prevent non-blocking, zero-copy transfer of data. Systems
such as IO-lite~~\cite{DBLP:journals/tocs/PaiDZ00} use memory
protection mechanisms to unify buffering.  \ix enables a zero-copy
model: on receive, it relies on memory protection to safely expose
incoming packets to an application; on send, \ix explicitly notifies the
application when the data has been acknowledged by the peer.



\paragraph{Adaptive, batched run to completion}

\todo TODO

\paragraph{Coherence-free, flow-consistent processing}

\todo Affinity Accept, mTCP, ...



\paragraph{API design.}


\paragraph{Hardware specialization - Dataplanes.}

\paragraph{Operating system architecture.}

\paragraph{Domain-specific and library operating systems.}


