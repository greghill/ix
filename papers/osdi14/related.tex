

\section{Related Work}
\label{sec:related}

We organize the discussion topically, while avoiding redundancy with
the commentary in \S\ref{sec:motivation:current}.

\myparagraph{Hardware virtualization:} Hardware support for
virtualization naturally separates control and execution functions,
e.g., to build type-2 hypervisors
~\cite{DBLP:journals/tocs/BugnionDRSW12,misc/kivity07kvm}, run virtual
appliances~\cite{DBLP:conf/lisa/SapuntzakisBCZCLR03}, or processes
with access to privileged instructions~\cite{dune}. Similar to \ix,
Arrakis uses hardware virtualization to separate the I/O dataplane
from the control plane~\cite{arrakis-osdi}. \ix differs in that it
uses the full Linux kernel for the control plane; provides three-way
isolation between control plane, networking protocol, and application
code; and proposes a dataplane architecture that optimizes for both
high throughput and low latency. 

\myparagraph{Library operating systems:} Exokernels extend the
end-to-end principle to resource management by implementing system
abstractions via library operating systems linked in with
applications~\cite{DBLP:conf/sosp/EnglerKO95}.  Library operating
systems typically run as virtual machines
~\cite{DBLP:journals/tocs/BugnionDGR97} used, for instance, to deploy
cloud services ~\cite{DBLP:conf/asplos/MadhavapeddyMRSSGSHC13}. \ix
limits itself to the implementation of the networking stack, allowing
applications to implement their own resource management policies,
e.g. via the \texttt{libevent} compatibility layer.

\begin{comment}
  \myparagraph{User-level networking stacks:} User-level network
  stacks~\cite{jeong2014mtcp, sandstorm, openonload} can outperform
  kernel-based implementations through specialization and elimination
  of redundant layers and abstractions, but trade-off performance for
  a weaker security model.  The \ix dataplane demonstrates that a
  specialized networking stack can offer performance and cooperate
  with applications without having to weaken security and isolation
  properties.
 
  \myparagraph{Hardware and protocol specialization:} Applications can
  use a connection-less UDP-based protocol for
  scalability~\cite{DBLP:conf/nsdi/NishtalaFGKLLMPPSSTV13}.
  Latency-sensitive datacenter applications can use specialized
  Infiniband adapters to expose RDMA with $1-3$\microsecond latencies
  to
  applications~\cite{dragojevic14farm,DBLP:conf/icpp/JoseSLZHWIOWSP11,
    mitchell:rdma, DBLP:conf/sosp/OngaroRSOR11}.  Specialized FGPAs
  can replace conventional servers for important applications such as
  memcached~\cite{DBLP:conf/hotcloud/BlottKLVBI13,DBLP:conf/fpga/ChalamalasettiLWARM13,HPHA:Tanaka:2014}.
  \ix is designed to allow TCP/IP to scale with architectural trends
  by eliminating kernel bottlenecks.
\end{comment}


\myparagraph{Asynchronous and zero-copy communication:} Systems with
asynchronous, batched, or exception-less system calls substantially
reduce the overheads associated with frequent kernel transitions and
context
switches~\cite{DBLP:conf/osdi/HanMCR12,jeong2014mtcp,DBLP:journals/cacm/Rizzo12,DBLP:conf/osdi/SoaresS10}. \ix's
use of adaptive batching shares similar benefits but is also suitable
for low-latency communication.  Zero-copy reduces data movement
overheads and simplifies resource
management~\cite{DBLP:journals/tocs/PaiDZ00}. POSIX OSes have been
modified to support zero-copy through page remapping and
copy-on-write~\cite{DBLP:conf/usenix/Chu96}, By contrast, \ix's
cooporative memory management enables zero-copy without page
remapping. Similar to \ix, TinyOS passes pointers to packet buffers
between the network stack and the application in a cooperative,
zero-copy fashion~\cite{tinyosnet}.  While both systems are
event-centric, \ix focuses on memory protection and datacenter
workloads, while TinyOS focuses on memory constrained, sensor
environments.
%\ix's use of adaptive,
%bounded batching is suitable for both low-latency and high-message
%rate, and its safe, cooperative memory management model enables
%zero-copy at the application level without page remapping. 


