
\section{Discussion}
\label{sec:disc}


\myparagraph{What makes \ix faster:} The results in \S\ref{sec:eval}
show that a networking stack can be implemented in a protected OS
kernel and still deliver wire-rate performance for most benchmarks.
The tight coupling of the dataplane architecture, using only a minimal
amount of batching to amortize transition costs, causes application
logic to be scheduled at the right time, which is essential for
latency-sensitive workloads.  Therefore, the benefits of \ix go beyond
just minimizing kernel overheads. Similar to
Exokernel~\cite{DBLP:conf/sosp/EnglerKO95}, the lack of intermediate
buffers pushes all abstractions outside of the OS kernel, allowing for
efficient, application-specific implementations.  In particular, the
zero-copy approach helps even when the user-level libraries add a
level of copying, as it is the case for compatibility interfaces in
our event library.  The extra copy occurs much closer to the actual
use, thereby increasing cache locality.  Finally, we took great care
in tuning the implementation of \ix for multi-core scalability,
eliminating constructs that introduce synchronization or coherence
traffic.

\myparagraph{Limitations of current prototype:} The current prototype
supports any stateless offload NIC with multiple queues and RSS
support. The NICs we currently use support RSS group of 16 queues,
which is inadequate given current multi-core trends. Nevertheless, the
trend in NICs seems to be towards support for larger number of
queues~\cite{radhakrishnan2014senic}. We also plan to explore using Intel's Flow
Director~\cite{intel:82599} to provide connection
affinity~\cite{DBLP:conf/eurosys/PesterevSZM12} as an alternative to
our current flow hashing implementation. Our current implementation
does not exploit IOMMUs or VT-d. Instead, it uses Dune to map
descriptor rings directly into \ix memory as a form of
paravirtualization~\cite{DBLP:conf/sosp/BarhamDFHHHN03}.  Although
this choice puts some level of trust into \ix, the applications remain
securely isolated.

\myparagraph{Future work:} This paper focused on the \ix dataplane
design. \ix is designed and implemented to support the dynamic
addition and removal of elastic threads in order to achieve energy
proportional and resource efficient computing. So far we have tested
only static configurations. In future work, we will design a dynamic
runtime that rebalances hardware queues between available elastic
threads in a manner that maintains throughput and latency constraints.
%
We will also explore the synergies between \ix and networking
protocols designed to support microsecond-level latencies and reduced
buffering characteristics of \ix deployments such as
DCTCP~\cite{DBLP:conf/sigcomm/AlizadehGMPPPSS10} and
ECN~\cite{ramakrishnan2001addition}. Finally, we will investigate \ix
implementations of alternative APIs, such as
MegaPipe~\cite{han2012megapipe}, cooperative
threading~\cite{capriccio}, and rule-based
models~\cite{stutsman_2013}.

